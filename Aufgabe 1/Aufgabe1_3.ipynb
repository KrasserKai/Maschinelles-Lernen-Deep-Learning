{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Implementierung der Hauptkomponentenanalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "%matplotlib inline\n",
    "%load_ext version_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Implementieren Sie ein Python-Modul, das eine Funktion zur Hauptkomponentenanalyse zur Verfügung stellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(data):\n",
    "\n",
    "    # Schritt 1.a: Mittelwert jedes Merkmals berechnen\n",
    "    num_data_points = len(data)\n",
    "    num_features = len(data[0])\n",
    "    mean_values = [0.0] * num_features\n",
    "    for i in range(num_data_points):\n",
    "        for j in range(num_features):\n",
    "            mean_values[j] += data[i][j]\n",
    "    for j in range(num_features):\n",
    "        mean_values[j] /= num_data_points\n",
    "\n",
    "    # Schritt 1.b: Daten zentrieren\n",
    "    centered_data = []\n",
    "\n",
    "    for i in range(num_data_points):\n",
    "        centered_point = []\n",
    "        for j in range(num_features):\n",
    "            centered_point.append(data[i][j] - mean_values[j])\n",
    "        centered_data.append(centered_point)\n",
    "\n",
    "    # Schritt 2: Daten normalisieren\n",
    "    normalized_data = []\n",
    "    min_values = [min(col) for col in zip(*centered_data)]\n",
    "    max_values = [max(col) for col in zip(*centered_data)]\n",
    "\n",
    "    for i in range(num_data_points):\n",
    "        normalized_point = []\n",
    "        for j in range(num_features):\n",
    "            normalized_value = (centered_data[i][j] - min_values[j]) / (max_values[j] - min_values[j])\n",
    "            normalized_point.append(normalized_value)\n",
    "        normalized_data.append(normalized_point)\n",
    "\n",
    "    # Schritt 3: Designmatrix erstellen\n",
    "    design_matrix = np.array(normalized_data)\n",
    "\n",
    "    # Schritt 4: Singulaerwertzerlegung von X berechnen\n",
    "    return np.linalg.svd(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Testen Sie Ihr Modul innerhalb eines IPython-Notebooks am Datensatz Boston Housing.\n",
    "### Lassen Sie dabei die Variable TGT weg. Stellen Sie Ihre Ergebnisse in einer Tabelle mit den Eigenwerten der Kovarianzmatrix (Achtung: die Diagonalelemente von müssen dafür quadriert und durch n − 1 geteilt werden. Warum?).\n",
    "-> Ist notwendig, um eine konsistente Schätzung der Kovarianzmatrix zu erhalten, wenn man mit Stichproben arbeitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'\n",
    "cols = ['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B',\n",
    "        'LSTAT','TGT']\n",
    "boston = pd.read_csv(url, sep=' ', skipinitialspace=True, header=None, names=cols, \n",
    "                     index_col=False)\n",
    "\n",
    "TGT = boston['TGT']\n",
    "del boston['TGT']\n",
    "data = boston.values.tolist()\n",
    "\n",
    "X = pca(data)\n",
    "U, D, Vt = X\n",
    "\n",
    "D = np.diag(D)\n",
    "\n",
    "n = len(D)\n",
    "a = {}\n",
    "for i in range(n):\n",
    "    a[i] = D[i][i]*D[i][i]/(n-1)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dem Anteil der zugehörigen Hauptkomponente an an der Gesamtvarianz (“erklärte Varianz”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sum(a)\n",
    "norm = [float(i)/s for i in a]\n",
    "norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### und der kumulativen erklärten Varianz dar, d.h. welchen Varianzanteil die ersten Komponenten zusammen erklären."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cumsum(norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wieviele Dimensionen können Sie weglassen, wenn Sie 10%, 5% und 1% Fehler bei der Dimensionsreduktion zulassen?\n",
    "10% - 4 Dimensionen\n",
    "5% - 3 Dimensionen\n",
    "1% - 2 Dimensionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Berechnen Sie die Matrix der Korrelationskoeffizienten für die transformierten Variablen und interpretieren Sie das Ergebnis.\n",
    "Korrelieren sehr schwach. Macht Sinn, ist schließlich der Zweck der PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_yes_no(v):\n",
    "    return f\"color: green;\" if v > 0.5 else f\"color: red;\"\n",
    "df = pd.DataFrame(pd.DataFrame(Vt).corr().abs())\n",
    "df.style.map(color_yes_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d.1) Berechnen Sie den Korrelationskoeffizienten der Projektionen auf die ersten drei Hauptkomponenten mit den ursprünglichen Variablen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC1 = U[:, 0]\n",
    "PC2 = U[:, 1]\n",
    "PC3 = U[:, 2]\n",
    "correlation_PC1 = np.corrcoef(PC1, data, rowvar=False)[0, 1:]\n",
    "correlation_PC2 = np.corrcoef(PC2, data, rowvar=False)[0, 1:]\n",
    "correlation_PC3 = np.corrcoef(PC3, data, rowvar=False)[0, 1:]\n",
    "print(correlation_PC1)\n",
    "print(correlation_PC2)\n",
    "print(correlation_PC3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d.2) Interpretieren Sie Ihr Ergebnis.\n",
    "\n",
    "Viele hohe Korrelationen.\n",
    "PC1 und PC2 korrelieren teilweise mit den gleichen Variablen, allerdings mit verschiedenem Vorzeichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e.1) Stellen Sie die ersten beiden der neuen Variablen als Scatterplot dar (am besten in Pandas-Dataframe importieren). Plotten Sie dabei alle Datenpunkte mit einem Hauspreis oberhalb des Medians aller Hauspreise in einer anderen Farbe als die Datenpunkte unterhalb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_tgt = TGT.median()\n",
    "col = np.where(TGT>median_tgt,'b','r')\n",
    "plt.scatter(PC1, TGT, c = col)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('TGT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(PC2, TGT, c = col)\n",
    "plt.xlabel('PC2')\n",
    "plt.ylabel('TGT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e.2) Eignen sich die beiden neuen Variablen zur Vorhersage des Hauspreises?\n",
    "\n",
    "Nein. Der Hauspreis streut sehr stark bei bestimmten Werten der Variablen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%version_information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
